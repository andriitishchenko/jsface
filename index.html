<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Bandera Faceer</title>
    <script src="camvas.js"></script>
    <script src="pico.js"></script>
    <script src="lploc.js"></script>
</head>
<script>
    var loaderProgress = 0;
    //ui
    var ctx = null;
    var canvas = null;

    //global vars
    var initialized = false;
    var facefinder_classify_region = null;
    var update_memory = null;
    var do_puploc = null;
    var banderaImg = new Image();

    var IS_DEBUG = false;

    var mycamvas = null;

    function initialize_pico() {
        if (initialized)
            return; // if yes, then do not initialize everything again
        /*
        	(1) initialize the pico.js face detector
        */
        update_memory = pico.instantiate_detection_memory(1); // we will use the detecions of the last 5 frames
        facefinder_classify_region = function(r, c, s, pixels, ldim) {
            return -1.0;
        };
        // var cascadeurl = 'https://raw.githubusercontent.com/nenadmarkus/pico/c2e81f9d23cc11d1a612fd21e4f9de0921a5d0d9/rnt/cascades/facefinder';
        var cascadeurl = 'facefinder';
        fetch(cascadeurl).then(function(response) {
                response.arrayBuffer().then(function(buffer) {
                    var bytes = new Int8Array(buffer);
                    facefinder_classify_region = pico.unpack_cascade(bytes);
                    console.log('* facefinder loaded');
                    updateLoader();
                })
            })
            /*
            	(2) initialize the lploc.js library with a pupil localizer
            */
        do_puploc = function(r, c, s, nperturbs, pixels, nrows, ncols, ldim) {
            return [-1.0, -1.0];
        };
        // var puplocurl = 'https://drone.nenadmarkus.com/data/blog-stuff/puploc.bin';
        var puplocurl = 'puploc.bin';
        fetch(puplocurl).then(function(response) {
                response.arrayBuffer().then(function(buffer) {
                    var bytes = new Int8Array(buffer);
                    do_puploc = lploc.unpack_localizer(bytes);
                    console.log('* puploc loaded');
                    updateLoader();
                })
            })
            /*
            	(3) get the drawing context on the canvas and define a function to transform an RGBA image to grayscale
            */
        initialized = true;
    }

    function rgba_to_grayscale(rgba, nrows, ncols) {
        var gray = new Uint8Array(nrows * ncols);
        for (var r = 0; r < nrows; ++r)
            for (var c = 0; c < ncols; ++c)
            // gray = 0.2*red + 0.7*green + 0.1*blue
                gray[r * ncols + c] = (2 * rgba[r * 4 * ncols + 4 * c + 0] + 7 * rgba[r * 4 * ncols + 4 * c + 1] + 1 * rgba[r * 4 * ncols + 4 * c + 2]) / 10;
        return gray;
    }


    function processfn(video, dt) {
        // render the video frame to the canvas element and extract RGBA pixel data
        ctx.drawImage(video, 0, 0);
        var sizeWidth = ctx.canvas.width;
        var sizeHeight = ctx.canvas.height;
        var rgba = ctx.getImageData(0, 0, sizeWidth, sizeHeight).data;
        // prepare input to `run_cascade`
        image = {
            "pixels": rgba_to_grayscale(rgba, sizeHeight, sizeWidth),
            "nrows": sizeHeight,
            "ncols": sizeWidth,
            "ldim": sizeWidth
        }
        params = {
                "shiftfactor": 0.1, // move the detection window by 10% of its size
                "minsize": 100, // minimum size of a face
                "maxsize": 1000, // maximum size of a face
                "scalefactor": 1.1 // for multiscale processing: resize the detection window by 10% when moving to the higher scale
            }
            // run the cascade over the frame and cluster the obtained detections
            // dets is an array that contains (r, c, s, q) quadruplets
            // (representing row, column, scale and detection score)
        dets = pico.run_cascade(image, facefinder_classify_region, params);
        dets = update_memory(dets);
        dets = pico.cluster_detections(dets, 0.2); // set IoU threshold to 0.2
        // draw detections
        for (i = 0; i < dets.length; ++i) {
            console.log(`i = ${i} , ?? = ${dets[i][3]}`);
            // check the detection score
            // if it's above the threshold, draw it
            // (the constant 50.0 is empirical: other cascades might require a different one)
            if (dets[i][3] > 50.0) {
                var r, c, s;
                //
                if (IS_DEBUG) {
                    ctx.beginPath();
                    ctx.arc(dets[i][1], dets[i][0], dets[i][2] / 2, 0, 2 * Math.PI, false);
                    ctx.lineWidth = 3;
                    ctx.strokeStyle = 'red';
                    ctx.stroke();
                }
                //
                // find the eye pupils for each detected face
                // starting regions for localization are initialized based on the face bounding box
                // (parameters are set empirically)
                // first eye


                var p1 = {
                    x: 0,
                    y: 0
                };

                var p2 = {
                    x: 0,
                    y: 0
                };



                r = dets[i][0] - 0.075 * dets[i][2];
                c = dets[i][1] - 0.175 * dets[i][2];
                s = 0.35 * dets[i][2];
                [r, c] = do_puploc(r, c, s, 63, image)
                if (r >= 0 && c >= 0) {
                    if (IS_DEBUG) {
                        ctx.beginPath();
                        ctx.arc(c, r, 1, 0, 2 * Math.PI, false);
                        ctx.lineWidth = 3;
                        ctx.strokeStyle = 'lime';
                        ctx.stroke();
                    }
                    p1.x = r;
                    p1.y = c;

                    p2.x = r;
                    p2.y = c;

                }
                // second eye
                r = dets[i][0] - 0.075 * dets[i][2];
                c = dets[i][1] + 0.175 * dets[i][2];
                s = 0.35 * dets[i][2];
                [r, c] = do_puploc(r, c, s, 63, image)
                if (r >= 0 && c >= 0) {
                    if (IS_DEBUG) {
                        ctx.beginPath();
                        ctx.arc(c, r, 1, 0, 2 * Math.PI, false);
                        ctx.lineWidth = 3;
                        ctx.strokeStyle = 'blue';
                        ctx.stroke();
                    }
                    p2.x = r;
                    p2.y = c;
                    if (p1.x == 0 && p1.y == 0) {
                        p1.x = r;
                        p1.y = c;
                    }
                }

                // apply a mask (banderaface)

                var face_heigth = dets[i][2] * 0.78;
                var banderaDX = banderaImg.width / banderaImg.height;
                var bh = face_heigth;
                var bw = face_heigth * banderaDX;


                var x = dets[i][1];
                var y = dets[i][0];

                var angleInRadians = Math.PI - (Math.atan2(p2.y - p1.y, p2.x - p1.x) + Math.PI / 2);
                ctx.translate(x, y);
                ctx.rotate(angleInRadians);
                ctx.drawImage(banderaImg, -bw / 2 + 10, -bh / 2 + 15, bw, bh);
                ctx.rotate(-angleInRadians);
                ctx.translate(-x, -y);
            }
        }
    }

    function button_callback() {
        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
        mycamvas = new camvas(ctx, processfn);
        update_memory = pico.instantiate_detection_memory(5);
    }

    function stopCamera() {
        if (mycamvas != null) {
            mycamvas.stop();
            mycamvas = null;
            update_memory = pico.instantiate_detection_memory(1);
        }
    }

    function button_loca_pic_callback() {
        stopCamera();
        var img = new Image();
        img.onload = onImageLoaded;
        img.crossOrigin = 'anonymous';
        img.src = 'test.jpg';
    }

    window.addEventListener("load", function(event) {
        initialize_pico();

        canvas = document.getElementsByTagName('canvas')[0];
        ctx = canvas.getContext('2d');

        banderaImg.crossOrigin = 'anonymous';
        banderaImg.src = 'bandera-face3.png';
    });


    function onImageLoaded(e) {
        updateWithNewImage(e.target);
    }

    function updateWithNewImage(img) {
        canvas.width = img.width;
        canvas.height = img.height;
        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
        processfn(img, null);
    }

    function loadImageFile() {
        stopCamera();
        var input = document.getElementById('imgfile');
        if (!input || !input.files) {
            return;
        } else {
            var file = input.files[0];
            var fr = new FileReader();
            fr.onload = function(e) {
                var img = new Image();
                img.crossOrigin = 'anonymous';
                img.onload = onImageLoaded;
                img.src = e.target.result;
            }
            fr.readAsDataURL(file);
        }
        input.value = "";
    }


    function updateLoader() {
        loaderProgress++;
        if (loaderProgress >= 2) {
            document.querySelectorAll('input').forEach(function(e) {
                e.removeAttribute('disabled');
            });
        }
    }
</script>

<body>
    <p>
        <input type="button" value="Start webcam feed" onclick="button_callback()" disabled/>
        <input type="button" value="Load test pic" onclick="button_loca_pic_callback()" disabled/>
        <input type='file' id='imgfile' onchange="loadImageFile()" disabled />
    </p>
    <hr>
    <p>
        <center><canvas id="canvas" width=640 height=480></canvas></center>
    </p>
    <hr>

</body>

</html>